from keras.layers import Input, Dense, Reshape, BatchNormalization, LeakyReLU, Dropout
from keras.layers import Conv2D, Conv2DTranspose, Flatten
from keras.models import Model, Sequential
from keras.optimizers import Adam
import numpy as np

# Load the data
X_train = np.load('X_train.npy')

# Normalize the data
X_train = X_train / 255.0

# Build the generator
gen = Sequential()
gen.add(Dense(7*7*256, input_dim=100))
gen.add(Reshape((7, 7, 256)))
gen.add(BatchNormalization())
gen.add(LeakyReLU(alpha=0.01))
gen.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))
gen.add(BatchNormalization())
gen.add(LeakyReLU(alpha=0.01))
gen.add(Conv2DTranspose(64, kernel_size=3, strides=2, padding='same'))
gen.add(BatchNormalization())
gen.add(LeakyReLU(alpha=0.01))
gen.add(Conv2DTranspose(3, kernel_size=3, strides=2, padding='same', activation='tanh'))

# Build the discriminator
disc = Sequential()
disc.add(Conv2D(32, kernel_size=3, strides=2, input_shape=(28, 28, 3), padding='same'))
disc.add(LeakyReLU(alpha=0.01))
disc.add(Dropout(0.3))
disc.add(Conv2D(64, kernel_size=3, strides=2, padding='same'))
disc.add(LeakyReLU(alpha=0.01))
disc.add(Dropout(0.3))
disc.add(Flatten())
disc.add(Dense(1, activation='sigmoid'))

# Compile the discriminator
disc.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy', metrics=['accuracy'])

# Build the GAN
gan_input = Input(shape=(100,))
gen_output = gen(gan_input)
gan_output = disc(gen_output)
